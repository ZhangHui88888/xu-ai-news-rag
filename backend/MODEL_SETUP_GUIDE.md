# XU-News-AI-RAG æ¨¡å‹é…ç½®æŒ‡å—

## ğŸ“¦ æ¨¡å‹æ¦‚å¿µè¯´æ˜

### 1ï¸âƒ£ åµŒå…¥æ¨¡å‹ï¼ˆEmbedding Modelï¼‰= å‘é‡æ¨¡å‹

**ä½œç”¨ï¼š** å°†æ–‡æœ¬è½¬æ¢ä¸ºé«˜ç»´å‘é‡ï¼ˆæ•°å€¼æ•°ç»„ï¼‰ï¼Œä½¿è®¡ç®—æœºèƒ½ç†è§£æ–‡æœ¬è¯­ä¹‰

```
æ–‡æœ¬ï¼š"ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"
     â†“ åµŒå…¥æ¨¡å‹
å‘é‡ï¼š[0.23, -0.45, 0.67, ..., 0.12]  # 768ç»´æµ®ç‚¹æ•°æ•°ç»„
```

**ä¸ºä»€ä¹ˆéœ€è¦ï¼š** 
- RAG ç³»ç»Ÿé€šè¿‡å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢ç›¸å…³æ–‡æ¡£
- è¯­ä¹‰ç›¸ä¼¼çš„æ–‡æœ¬ï¼Œå‘é‡è·ç¦»æ›´è¿‘

### 2ï¸âƒ£ é‡æ’æ¨¡å‹ï¼ˆReranker Modelï¼‰

**ä½œç”¨ï¼š** å¯¹åˆæ­¥æ£€ç´¢çš„ç»“æœé‡æ–°ç²¾ç¡®æ’åºï¼Œæé«˜å‡†ç¡®ç‡

```
æ£€ç´¢é˜¶æ®µï¼šå‘é‡ç›¸ä¼¼åº¦å¿«é€Ÿç­›é€‰å‡º Top 50 ä¸ªå€™é€‰æ–‡æ¡£ (å¬å›)
é‡æ’é˜¶æ®µï¼šç²¾ç¡®è®¡ç®—ç›¸å…³æ€§ï¼Œé€‰å‡ºæœ€ç›¸å…³çš„ Top 5 (ç²¾æ’)
```

**ä¸ºä»€ä¹ˆéœ€è¦ï¼š** 
- å‘é‡æ£€ç´¢é€Ÿåº¦å¿«ä½†ä¸å¤Ÿç²¾ç¡®
- é‡æ’æ¨¡å‹è®¡ç®—é‡å¤§ä½†æ›´å‡†ç¡®
- ä¸¤è€…ç»“åˆè¾¾åˆ°é€Ÿåº¦å’Œç²¾åº¦çš„å¹³è¡¡

### 3ï¸âƒ£ å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰

**ä½œç”¨ï¼š** ç†è§£é—®é¢˜ï¼ŒåŸºäºæ£€ç´¢çš„æ–‡æ¡£ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

```
ç”¨æˆ·é—®é¢˜ + æ£€ç´¢æ–‡æ¡£ â†’ LLM â†’ æµç•…è‡ªç„¶çš„å›ç­”
```

---

## ğŸš€ å¿«é€Ÿé…ç½®ï¼ˆ3ç§æ–¹æ¡ˆï¼‰

### æ–¹æ¡ˆä¸€ï¼šOllama æœ¬åœ°éƒ¨ç½²ï¼ˆæ¨èï¼‰

#### 1. å®‰è£… Ollama

**Windows:**
```powershell
# ä¸‹è½½å¹¶å®‰è£… Ollama
# https://ollama.com/download

# éªŒè¯å®‰è£…
ollama --version
```

**Linux/Mac:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

#### 2. ä¸‹è½½æ¨èæ¨¡å‹

```bash
# 1. åµŒå…¥æ¨¡å‹ï¼ˆå‘é‡åŒ–ï¼‰
ollama pull nomic-embed-text        # 768ç»´ï¼Œ137MBï¼Œé€Ÿåº¦å¿«
# æˆ–è€…
ollama pull all-minilm:l6-v2       # 384ç»´ï¼Œæ›´å°ä½†æ•ˆæœç¨é€Š

# 2. å¤§è¯­è¨€æ¨¡å‹ï¼ˆæ–‡æœ¬ç”Ÿæˆï¼‰
ollama pull qwen2.5:3b             # ä¸­æ–‡å‹å¥½ï¼Œ3Bå‚æ•°
# æˆ–è€…
ollama pull qwen2.5:7b             # æ•ˆæœæ›´å¥½ï¼Œéœ€è¦æ›´å¤šå†…å­˜

# 3. æµ‹è¯•æ¨¡å‹
ollama run qwen2.5:3b "ä½ å¥½"
```

#### 3. é…ç½®é¡¹ç›®

ä¿®æ”¹ `application.yml`:

```yaml
# Ollamaé…ç½®
ollama:
  base-url: http://localhost:11434
  model:
    llm: qwen2.5:3b                      # å¤§è¯­è¨€æ¨¡å‹
    embedding: nomic-embed-text:latest   # åµŒå…¥æ¨¡å‹ï¼ˆå‘é‡æ¨¡å‹ï¼‰
  timeout: 60000

# FAISSå‘é‡åº“é…ç½®
faiss:
  index-path: ./data/faiss_index
  dimension: 768  # å¿…é¡»ä¸åµŒå…¥æ¨¡å‹ç»´åº¦åŒ¹é…
```

**æ³¨æ„ï¼š** 
- `nomic-embed-text` è¾“å‡º 768 ç»´å‘é‡
- `all-minilm:l6-v2` è¾“å‡º 384 ç»´å‘é‡
- ä¿®æ”¹æ¨¡å‹æ—¶å¿…é¡»åŒæ—¶ä¿®æ”¹ `dimension` é…ç½®

#### 4. éªŒè¯é…ç½®

```bash
# æµ‹è¯•åµŒå…¥æ¨¡å‹
curl http://localhost:11434/api/embeddings \
  -d '{
    "model": "nomic-embed-text",
    "prompt": "æµ‹è¯•æ–‡æœ¬"
  }'

# æµ‹è¯• LLM
curl http://localhost:11434/api/generate \
  -d '{
    "model": "qwen2.5:3b",
    "prompt": "ä»€ä¹ˆæ˜¯RAGï¼Ÿ",
    "stream": false
  }'
```

---

### æ–¹æ¡ˆäºŒï¼šä½¿ç”¨ Sentence-Transformersï¼ˆPythonï¼‰

#### 1. åˆ›å»º Python æœåŠ¡

**åˆ›å»º `embedding_service.py`:**

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from sentence_transformers import SentenceTransformer, CrossEncoder
from typing import List
import numpy as np

app = FastAPI()

# 1. åŠ è½½åµŒå…¥æ¨¡å‹
embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # 384ç»´

# 2. åŠ è½½é‡æ’æ¨¡å‹
reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

# åµŒå…¥è¯·æ±‚
class EmbeddingRequest(BaseModel):
    text: str

# é‡æ’è¯·æ±‚
class RerankRequest(BaseModel):
    query: str
    documents: List[str]

@app.post("/embed")
def embed(request: EmbeddingRequest):
    """ç”Ÿæˆæ–‡æœ¬åµŒå…¥å‘é‡"""
    try:
        embedding = embedding_model.encode(request.text)
        return {
            "embedding": embedding.tolist(),
            "dimension": len(embedding)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/rerank")
def rerank(request: RerankRequest):
    """å¯¹æ£€ç´¢ç»“æœé‡æ–°æ’åº"""
    try:
        # æ„å»ºæŸ¥è¯¢-æ–‡æ¡£å¯¹
        pairs = [[request.query, doc] for doc in request.documents]
        
        # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
        scores = reranker.predict(pairs)
        
        # æŒ‰åˆ†æ•°æ’åº
        ranked_results = sorted(
            enumerate(scores), 
            key=lambda x: x[1], 
            reverse=True
        )
        
        return {
            "ranked_indices": [idx for idx, _ in ranked_results],
            "scores": [float(score) for _, score in ranked_results]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

#### 2. å®‰è£…ä¾èµ–

```bash
pip install fastapi uvicorn sentence-transformers torch
```

#### 3. å¯åŠ¨æœåŠ¡

```bash
python embedding_service.py
```

#### 4. ä¿®æ”¹ Java ä»£ç 

åˆ›å»º `EmbeddingServiceClient.java`:

```java
@Component
public class EmbeddingServiceClient {
    
    @Value("${embedding.service.url}")
    private String serviceUrl;
    
    private final RestTemplate restTemplate = new RestTemplate();
    
    public List<Double> generateEmbedding(String text) {
        Map<String, String> request = Map.of("text", text);
        
        ResponseEntity<Map> response = restTemplate.postForEntity(
            serviceUrl + "/embed", 
            request, 
            Map.class
        );
        
        return (List<Double>) response.getBody().get("embedding");
    }
    
    public List<Integer> rerank(String query, List<String> documents) {
        Map<String, Object> request = Map.of(
            "query", query,
            "documents", documents
        );
        
        ResponseEntity<Map> response = restTemplate.postForEntity(
            serviceUrl + "/rerank", 
            request, 
            Map.class
        );
        
        return (List<Integer>) response.getBody().get("ranked_indices");
    }
}
```

é…ç½® `application.yml`:

```yaml
embedding:
  service:
    url: http://localhost:8000
```

---

### æ–¹æ¡ˆä¸‰ï¼šä½¿ç”¨äº‘ç«¯ APIï¼ˆOpenAI / æ™ºè°±AIï¼‰

#### OpenAI é…ç½®

```yaml
openai:
  api-key: ${OPENAI_API_KEY}
  base-url: https://api.openai.com/v1
  models:
    embedding: text-embedding-3-small  # 1536ç»´
    llm: gpt-4o-mini
```

#### æ™ºè°±AI é…ç½®ï¼ˆå›½å†…æ¨èï¼‰

```yaml
zhipu:
  api-key: ${ZHIPU_API_KEY}
  base-url: https://open.bigmodel.cn/api/paas/v4
  models:
    embedding: embedding-2  # 1024ç»´
    llm: glm-4-flash
```

---

## ğŸ” æ·»åŠ é‡æ’æ¨¡å‹ï¼ˆRerankerï¼‰

### ä¸ºä»€ä¹ˆéœ€è¦é‡æ’ï¼Ÿ

```
åœºæ™¯ï¼šç”¨æˆ·é—®"Pythonå¦‚ä½•è¯»å–æ–‡ä»¶ï¼Ÿ"

å‘é‡æ£€ç´¢ç»“æœï¼ˆTop 5ï¼‰ï¼š
1. "Pythonæ–‡ä»¶æ“ä½œè¯¦è§£" - ç›¸ä¼¼åº¦ 0.82
2. "æ–‡ä»¶ç³»ç»ŸåŸç†"      - ç›¸ä¼¼åº¦ 0.79
3. "PythonåŸºç¡€æ•™ç¨‹"    - ç›¸ä¼¼åº¦ 0.78
4. "è¯»å–Excelæ–‡ä»¶"     - ç›¸ä¼¼åº¦ 0.76
5. "Pythonæ–‡ä»¶è¯»å†™"    - ç›¸ä¼¼åº¦ 0.75

é‡æ’åï¼š
1. "Pythonæ–‡ä»¶è¯»å†™"    - ç²¾ç¡®ç›¸å…³åº¦ 0.95 â¬†ï¸
2. "Pythonæ–‡ä»¶æ“ä½œè¯¦è§£" - ç²¾ç¡®ç›¸å…³åº¦ 0.91
3. "è¯»å–Excelæ–‡ä»¶"     - ç²¾ç¡®ç›¸å…³åº¦ 0.73 â¬†ï¸
4. "PythonåŸºç¡€æ•™ç¨‹"    - ç²¾ç¡®ç›¸å…³åº¦ 0.65
5. "æ–‡ä»¶ç³»ç»ŸåŸç†"      - ç²¾ç¡®ç›¸å…³åº¦ 0.58 â¬‡ï¸
```

### å®ç°æ­¥éª¤

#### 1. ä¿®æ”¹ `QueryServiceImpl.java`

```java
@Service
public class QueryServiceImpl implements QueryService {
    
    @Autowired
    private OllamaClient ollamaClient;
    
    @Autowired
    private VectorStore vectorStore;
    
    @Autowired
    private KnowledgeEntryService knowledgeEntryService;
    
    @Autowired
    private EmbeddingServiceClient embeddingService;  // æ–°å¢
    
    @Override
    public QueryResponse query(QueryRequest request, Long userId) throws IOException {
        
        // Step 1: å‘é‡æ£€ç´¢ï¼ˆå¬å›æ›´å¤šå€™é€‰ï¼‰
        List<Double> queryVector = ollamaClient.generateEmbedding(request.getQuery());
        
        // æ£€ç´¢ Top 20 ä¸ªå€™é€‰ï¼ˆè€Œä¸æ˜¯ç›´æ¥å– Top 5ï¼‰
        int candidateCount = request.getTopK() * 4;  // æ‰©å¤§å¬å›èŒƒå›´
        List<VectorStore.SearchResult> searchResults = vectorStore.search(
            queryVector, 
            candidateCount
        );
        
        // Step 2: è·å–å€™é€‰æ–‡æ¡£
        List<Long> vectorIds = searchResults.stream()
            .map(VectorStore.SearchResult::getVectorId)
            .collect(Collectors.toList());
        
        List<KnowledgeEntry> entries = knowledgeEntryService.findByVectorIds(vectorIds);
        
        // Step 3: é‡æ’åºï¼ˆç²¾æ’ï¼‰
        List<String> documents = entries.stream()
            .map(e -> e.getTitle() + "\n" + e.getContent())
            .collect(Collectors.toList());
        
        List<Integer> rankedIndices = embeddingService.rerank(
            request.getQuery(), 
            documents
        );
        
        // æŒ‰é‡æ’ç»“æœé‡æ–°æ’åºæ–‡æ¡£
        List<KnowledgeEntry> rerankedEntries = rankedIndices.stream()
            .limit(request.getTopK())  // åªå– Top K
            .map(entries::get)
            .collect(Collectors.toList());
        
        // Step 4: æ„å»º RAG æç¤ºè¯
        List<String> context = rerankedEntries.stream()
            .map(KnowledgeEntry::getContent)
            .collect(Collectors.toList());
        
        // Step 5: ç”Ÿæˆç­”æ¡ˆ
        String answer = ollamaClient.generateAnswer(request.getQuery(), context);
        
        // è¿”å›å“åº”...
    }
}
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æ–¹æ¡ˆ | åµŒå…¥æ¨¡å‹ | å‘é‡ç»´åº¦ | é€Ÿåº¦ | æ•ˆæœ | æˆæœ¬ |
|-----|---------|---------|------|------|------|
| **Ollama + nomic-embed-text** | nomic-embed-text | 768 | âš¡âš¡âš¡ | â­â­â­â­ | ğŸ’° å…è´¹ |
| **Sentence-Transformers** | all-MiniLM-L6-v2 | 384 | âš¡âš¡âš¡ | â­â­â­ | ğŸ’° å…è´¹ |
| **OpenAI API** | text-embedding-3-small | 1536 | âš¡âš¡ | â­â­â­â­â­ | ğŸ’°ğŸ’° $0.02/1M tokens |
| **æ™ºè°±AI** | embedding-2 | 1024 | âš¡âš¡ | â­â­â­â­ | ğŸ’° $0.005/1K tokens |

**æ¨èç»„åˆï¼š**
- ğŸ’¡ **å¼€å‘/å°å‹é¡¹ç›®ï¼š** Ollama (nomic-embed-text + qwen2.5:3b)
- ğŸš€ **ç”Ÿäº§ç¯å¢ƒï¼š** Ollama + Python é‡æ’æœåŠ¡
- â˜ï¸ **ä¼ä¸šçº§ï¼š** OpenAI API / æ™ºè°±AI

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜1: å‘é‡ç»´åº¦ä¸åŒ¹é…

**é”™è¯¯ï¼š** `å‘é‡ç»´åº¦ä¸åŒ¹é…ï¼ŒæœŸæœ›: 768, å®é™…: 384`

**åŸå› ï¼š** æ›´æ¢äº†åµŒå…¥æ¨¡å‹ä½†æœªæ›´æ–°é…ç½®

**è§£å†³ï¼š**
```yaml
faiss:
  dimension: 384  # æ”¹ä¸ºæ–°æ¨¡å‹çš„ç»´åº¦
```

### é—®é¢˜2: Ollama è°ƒç”¨å¤±è´¥

**æ£€æŸ¥æ¸…å•ï¼š**
```bash
# 1. æ£€æŸ¥ Ollama æ˜¯å¦è¿è¡Œ
curl http://localhost:11434/api/version

# 2. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½
ollama list

# 3. æµ‹è¯•åµŒå…¥æ¨¡å‹
ollama run nomic-embed-text
```

### é—®é¢˜3: æ£€ç´¢æ•ˆæœä¸å¥½

**ä¼˜åŒ–å»ºè®®ï¼š**
1. **å¢åŠ å‘é‡ç»´åº¦ï¼š** ä½¿ç”¨æ›´å¤§çš„åµŒå…¥æ¨¡å‹
2. **æ·»åŠ é‡æ’æ¨¡å‹ï¼š** æé«˜ç²¾ç¡®åº¦
3. **è°ƒæ•´æ£€ç´¢å‚æ•°ï¼š** 
   - å¢åŠ  `topK` æ•°é‡
   - é™ä½ `similarityThreshold`
4. **ä¼˜åŒ–æ–‡æœ¬é¢„å¤„ç†ï¼š** æ¸…ç†æ— ç”¨å­—ç¬¦ã€åˆ†æ®µç­‰

---

## ğŸ“š å‚è€ƒèµ„æº

- [Ollama å®˜æ–¹æ–‡æ¡£](https://ollama.com/library)
- [Sentence-Transformers æ–‡æ¡£](https://www.sbert.net/)
- [FAISS å‘é‡åº“](https://github.com/facebookresearch/faiss)
- [Hugging Face æ¨¡å‹åº“](https://huggingface.co/models)

---

**ç¥æ‚¨é…ç½®é¡ºåˆ©ï¼å¦‚æœ‰é—®é¢˜æ¬¢è¿åé¦ˆã€‚ğŸ‰**

